{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2020_okimoki_학습활동.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxlEqhUormy5",
        "colab_type": "text"
      },
      "source": [
        "> # **[2020 학습활동]**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFemvBa5rxxY",
        "colab_type": "text"
      },
      "source": [
        "> # **Day 1. 사전 훈련된 컨브넷(VGG16) 활용**\n",
        "2020.05.26. Fri"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXDnvsJgsdXV",
        "colab_type": "text"
      },
      "source": [
        "# **ABSTRACT**: ImageNet data로 사전 훈련된 ConvNet 모델(VGG16)을 활용하여 이미지 이진 분류 모델(고양이 vs 개) 만들어보기\n",
        "# **KEYWORD**: ConvNet, VGG16, ImageNet, Feature Exctraction, Classification Layer\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWTmiEdJudVw",
        "colab_type": "text"
      },
      "source": [
        "> # **1. Data 다운로드 및 전처리**\n",
        "출처: kaggle 강아지 vs 고양이 데이터 (https://www.kaggle.com/c/dogs-vs-cats/data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ADrfSjhughb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터가 이미 있을경우 삭제\n",
        "!rm -rf datasets\n",
        "# 데이터 다운로드\n",
        "!git clone http://gitlab.com/jooncco/datasets\n",
        "# 압축 해제\n",
        "!cd datasets && unzip dogs-vs-cats.zip && mkdir cats_and_dogs && mv ./train.zip ./cats_and_dogs/train.zip && cd cats_and_dogs && unzip train.zip && rm train.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEqGEq3mWIP-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf ./datasets/cats_and_dogs_small\n",
        "\n",
        "import os, shutil\n",
        "\n",
        "# 이미지 파일이 있는 colab 가상 파일시스템의 경로\n",
        "original_dataset_dir= './datasets/cats_and_dogs/train'\n",
        "\n",
        "base_dir= './datasets/cats_and_dogs_small'            # 소규모 데이터셋을 저장할 경로\n",
        "os.mkdir(base_dir)\n",
        "\n",
        "# 훈련/검증/테스트 데이터 디렉토리 생성\n",
        "train_dir= os.path.join(base_dir, 'train')            # 훈련 데이터 directory\n",
        "os.mkdir(train_dir)\n",
        "validation_dir= os.path.join(base_dir, 'validation')  # 검증 데이터 directory\n",
        "os.mkdir(validation_dir)\n",
        "test_dir= os.path.join(base_dir, 'test')              # 테스트 데이터 directory\n",
        "os.mkdir(test_dir)\n",
        "\n",
        "train_cats_dir= os.path.join(train_dir, 'cats')                 # 훈련용 고양이 사진 directory\n",
        "os.mkdir(train_cats_dir)\n",
        "train_dogs_dir= os.path.join(train_dir, 'dogs')                 # 훈련용 강아지 사진 directory\n",
        "os.mkdir(train_dogs_dir)\n",
        "validation_cats_dir= os.path.join(validation_dir, 'cats')       # 검증용 고양이 사진 directory\n",
        "os.mkdir(validation_cats_dir)\n",
        "validation_dogs_dir= os.path.join(validation_dir, 'dogs')       # 검증용 강아지 사진 directory\n",
        "os.mkdir(validation_dogs_dir)\n",
        "test_cats_dir= os.path.join(test_dir, 'cats')                   # 테스트용 고양이 사진 directory\n",
        "os.mkdir(test_cats_dir)\n",
        "test_dogs_dir= os.path.join(test_dir, 'dogs')                   # 테스트용 강아지 사진 directory\n",
        "os.mkdir(test_dogs_dir)\n",
        "\n",
        "\n",
        "# 고양이 사진들을 훈련/검증/테스트 용으로 분할하기\n",
        "fnames= ['cat.{}.jpg'.format(i) for i in range(1000)]                # 처음 1000장의 고양이 사진을 train_cats_dir에 복사\n",
        "for fname in fnames:\n",
        "  src= os.path.join(original_dataset_dir,fname)     # 원본 경로\n",
        "  dst= os.path.join(train_cats_dir,fname)           # 옮겨질 경로\n",
        "  shutil.copyfile(src,dst)\n",
        "\n",
        "fnames= ['cat.{}.jpg'.format(i) for i in range(1000,1500)]           # 다음 500장의 고양이 사진을 validation_cats_dir에 복사\n",
        "for fname in fnames:\n",
        "  src= os.path.join(original_dataset_dir,fname)     # 원본 경로\n",
        "  dst= os.path.join(validation_cats_dir,fname)      # 옮겨질 경로\n",
        "  shutil.copyfile(src,dst)\n",
        "\n",
        "fnames= ['cat.{}.jpg'.format(i) for i in range(1500,2000)]           # 다음 500장의 고양이 사진을 test_cats_dir 복사\n",
        "for fname in fnames:\n",
        "  src= os.path.join(original_dataset_dir,fname)     # 원본 경로\n",
        "  dst= os.path.join(test_cats_dir,fname)            # 옮겨질 경로\n",
        "  shutil.copyfile(src,dst)\n",
        "\n",
        "# 강아지 사진들을 훈련/검증/테스트 용으로 분할하기\n",
        "fnames= ['dog.{}.jpg'.format(i) for i in range(1000)]                # 처음 1000장의 강아지 사진을 train_cats_dir에 복사\n",
        "for fname in fnames:\n",
        "  src= os.path.join(original_dataset_dir,fname)     # 원본 경로\n",
        "  dst= os.path.join(train_dogs_dir,fname)           # 옮겨질 경로\n",
        "  shutil.copyfile(src,dst)\n",
        "\n",
        "fnames= ['dog.{}.jpg'.format(i) for i in range(1000,1500)]           # 다음 500장의 강아지 사진을 validation_cats_dir에 복사\n",
        "for fname in fnames:\n",
        "  src= os.path.join(original_dataset_dir,fname)     # 원본 경로\n",
        "  dst= os.path.join(validation_dogs_dir,fname)      # 옮겨질 경로\n",
        "  shutil.copyfile(src,dst)\n",
        "\n",
        "fnames= ['dog.{}.jpg'.format(i) for i in range(1500,2000)]           # 다음 500장의 강아지 사진을 test_cats_dir 복사\n",
        "for fname in fnames:\n",
        "  src= os.path.join(original_dataset_dir,fname)     # 원본 경로\n",
        "  dst= os.path.join(test_dogs_dir,fname)            # 옮겨질 경로\n",
        "  shutil.copyfile(src,dst)\n",
        "\n",
        "# 잘 옮겨졌나?\n",
        "print(\"훈련용 고양이 이미지 전체 개수: \", len(os.listdir(train_cats_dir)))\n",
        "print(\"검증용 고양이 이미지 전체 개수: \", len(os.listdir(validation_cats_dir)))\n",
        "print(\"테스트용 고양이 이미지 전체 개수: \", len(os.listdir(test_cats_dir)))\n",
        "print(\"훈련용 강아지 이미지 전체 개수: \", len(os.listdir(train_dogs_dir)))\n",
        "print(\"검증용 강아지 이미지 전체 개수: \", len(os.listdir(validation_dogs_dir)))\n",
        "print(\"테스트용 고양이 이미지 전체 개수: \", len(os.listdir(test_dogs_dir)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERtBUi-huOy8",
        "colab_type": "text"
      },
      "source": [
        "> # **2. ConvNet(VGG16) 준비**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MsD9ktetRcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications import VGG16\n",
        "\n",
        "conv_base= VGG16(weights= 'imagenet',          # imagenet 데이터로 미리 학습된 weight들을 로드\n",
        "                 include_top= False,           # Fully connected classifier 층은 제외\n",
        "                 input_shape= (150,150,3))     # 150 x 150 pixel의 rgb값이 들어있는 텐서를 input으로 받음\n",
        "conv_base.summary()       # 내 모델을 보여줘"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2XJfx831RWb",
        "colab_type": "text"
      },
      "source": [
        "> # **3. 특성 추출 (Feature Extraction)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLdE31xd1dl8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "base_dir= './datasets/cats_and_dogs_small'              # 루트 디렉토리\n",
        "train_dir= os.path.join(base_dir, 'train')              # 훈련 데이터 디렉토리\n",
        "validation_dir= os.path.join(base_dir, 'validation')    # 훈련 검증 데이터 디렉토리\n",
        "test_dir= os.path.join(base_dir, 'test')                # 테스트 데이터 디렉토리\n",
        "\n",
        "datagen= ImageDataGenerator(rescale=1.0/255)            # 픽셀 하나를 2^8 (1byte)의 범위를 갖는 rgb 값으로 환산하겠다.\n",
        "batch_size= 20                                          # 샘플 데이터를 이 크기의 배치로 분할\n",
        "\n",
        "\n",
        "# 이미지 데이터에서 추출한 feature 들을 리턴해주는 함수\n",
        "def extract_features(directory, sample_count):\n",
        "  features= np.zeros(shape= (sample_count, 4, 4, 512))            # 데이터들을 모델이 처리한 결과(features)가 담길 numpy array\n",
        "  labels= np.zeros(shape= (sample_count))                         # label 이 담길 numpy array\n",
        "  generator= datagen.flow_from_directory(directory,\n",
        "                                         target_size= (150,150),  # input data: 150 x 150\n",
        "                                         batch_size= batch_size,\n",
        "                                         class_mode= 'binary')    # 이중 분류 (강아지 vs 고양이)\n",
        "\n",
        "  i= 0\n",
        "  for inputs_batch, labels_batch in generator:\n",
        "    features_batch= conv_base.predict(inputs_batch)                 # 배치 하나의 예측 결과를 담은 numpy array\n",
        "    features[i * batch_size : (i+1) * batch_size]= features_batch   # write\n",
        "    labels[i * batch_size : (i+1) * batch_size]= labels_batch       # write\n",
        "    \n",
        "    i += 1\n",
        "    if (i * batch_size >= sample_count):\n",
        "      break                                 # 무한루프 탈출\n",
        "  return features, labels\n",
        "\n",
        "train_features, train_labels= extract_features(train_dir, 2000)                   # 훈련을 위한 feature extraction 결과\n",
        "validation_features, validation_labels= extract_features(validation_dir, 1000)    # 훈련 검증을 위한 feature extraction 결과\n",
        "test_features, test_labels= extract_features(test_dir, 1000)                      # 테스트를 위한 feature extraction 결과\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQnNqAtQ6U0U",
        "colab_type": "text"
      },
      "source": [
        "> # **4. 분류기 정의 (Classification Output Layer)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3znbSIAG6kjW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import models\n",
        "from keras import layers            # layer들을 레고 블럭처럼\n",
        "from keras import optimizers        # weight 업데이트 해주는 녀석\n",
        "\n",
        "\n",
        "model= models.Sequential()\n",
        "model.add(layers.Dense(256, activation= 'relu', input_dim= 4*4*512))            # layer 1: 밀집       ##################### 1.수정가능 (activation)\n",
        "model.add(layers.Dropout(0.5))                                                  # layer 2: Dropout    ##################### 2.수정가능 (Dropout argument)\n",
        "model.add(layers.Dense(1, activation='sigmoid'))                                # layer 3: 밀집       ##################### 3.수정가능 (activation)\n",
        "model.compile(optimizer= optimizers.RMSprop(lr= 2e-5),                          # optimizer 정의      ##################### 4.수정가능 (lr) <= 현재값: 2 x 10^(-5)\n",
        "              loss= 'binary_crossentropy',                                      # loss function 정의  ##################### 5.수정가능 (loss)\n",
        "              metrics= ['acc'])\n",
        "model.summary()                 # 내 모델을 보여줘\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExwNP-bp7q29",
        "colab_type": "text"
      },
      "source": [
        "> # **5. 훈련**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbX-fjhb7v-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# 분류기의 input_dim이 (4 x 4 x 512) 이기 때문에 feature를 (sample_count x 8192)로 펼쳐준다.\n",
        "train_features= np.reshape(train_features, (2000, 4 * 4 * 512))\n",
        "validation_features= np.reshape(validation_features, (1000, 4 * 4 * 512))\n",
        "test_features= np.reshape(test_features, (1000, 4 * 4 * 512))\n",
        "\n",
        "# 학습\n",
        "learn_history= model.fit(train_features, train_labels,\n",
        "                         epochs= 30,                                                            # 학습 반복 회수(epoch) 설정      ##################### 6.수정가능 (epochs)\n",
        "                         batch_size= 20,                                                        # batch 사이즈 설정               ##################### 7.수정가능 (batch_size)\n",
        "                         validation_data= (validation_features, validation_labels))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xe89AXCo8x7o",
        "colab_type": "text"
      },
      "source": [
        "> # **6. 훈련 결과 Plot**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8Mwxx7f8-hG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc= learn_history.history['acc']\n",
        "val_acc= learn_history.history['val_acc']\n",
        "loss= learn_history.history['loss']\n",
        "val_loss= learn_history.history['val_loss']\n",
        "\n",
        "# 그래프의 x축\n",
        "epochs= range(1, len(acc)+1)\n",
        "\n",
        "# epoch별 정확도 변화 그래프\n",
        "plt.plot(epochs, acc, 'bo', label= 'Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label= 'Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "# epoch별 손실값 변화 그래프\n",
        "plt.plot(epochs, acc, 'bo', label= 'Training loss')\n",
        "plt.plot(epochs, val_acc, 'b', label= 'Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSdxfJ97BJwH",
        "colab_type": "text"
      },
      "source": [
        "> # **7. 남은 과제 및 challenge**\n",
        "\n",
        "**>> Hyper-parameter 수정하여 최고 정확도 달성하기 <<**\n",
        "*  수정가능한 Hyper-parameter: (소스코드의 **'##################수정가능'** 주석)\n",
        "\n",
        "\n",
        "> # **Reference.**\n",
        "\n",
        "\n",
        "1. 강아지 vs 고양이 데이터 (https://www.kaggle.com/c/dogs-vs-cats/data)\n",
        "2. About ImageNet data: https://deepestdocs.readthedocs.io/en/latest/003_image_processing/0031/\n",
        "3. About ILSVRC: https://bskyvision.com/425\n",
        "4. \"케라스 창시자에게 배우는 딥러닝\", 프랑소와 숄레, 길벗, 2018)\n",
        "\n"
      ]
    }
  ]
}